{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7ee359",
   "metadata": {},
   "source": [
    "4.1.2 파이토치로 MLP 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bdc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치를 사용한 MLP\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size=2, output_size=3, \n",
    "                 num_hidden_layers=1, hidden_activation=nn.Sigmoid):\n",
    "        \"\"\"가중치 초기화\n",
    "\n",
    "        매개변수:\n",
    "            input_size (int): 입력 크기\n",
    "            hidden_size (int): 은닉층 크기\n",
    "            output_size (int): 출력 크기\n",
    "            num_hidden_layers (int): 은닉층 개수\n",
    "            hidden_activation (torch.nn.*): 활성화 함수\n",
    "        \"\"\"\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        self.module_list = nn.ModuleList()\n",
    "        \n",
    "        interim_input_size = input_size\n",
    "        interim_output_size = hidden_size\n",
    "        \n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.module_list.append(nn.Linear(interim_input_size, interim_output_size))\n",
    "            self.module_list.append(hidden_activation())\n",
    "            interim_input_size = interim_output_size\n",
    "            \n",
    "        self.fc_final = nn.Linear(interim_input_size, output_size)\n",
    "        \n",
    "        self.last_forward_cache = []\n",
    "       \n",
    "    def forward(self, x, apply_softmax=False):\n",
    "        \"\"\"MLP의 정방향 계산\n",
    "        \n",
    "        매개변수:\n",
    "            x_in (torch.Tensor): 입력 데이터 텐서\n",
    "                x_in.shape는 (batch, input_dim)입니다.\n",
    "            apply_softmax (bool): 소프트맥스 함수를 위한 플래그\n",
    "                크로스 엔트로피 손실을 사용하려면 반드시 False로 지정해야 합니다\n",
    "        반환값:\n",
    "            결과 텐서. tensor.shape는 (batch, output_dim)입니다.\n",
    "        \"\"\"\n",
    "        self.last_forward_cache = []\n",
    "        self.last_forward_cache.append(x.to(\"cpu\").numpy())\n",
    "\n",
    "        for module in self.module_list:\n",
    "            x = module(x)\n",
    "            self.last_forward_cache.append(x.to(\"cpu\").data.numpy())\n",
    "            \n",
    "        output = self.fc_final(x)\n",
    "        self.last_forward_cache.append(output.to(\"cpu\").data.numpy())\n",
    "\n",
    "        if apply_softmax:\n",
    "            output = F.softmax(output, dim=1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268edbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (module_list): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=100, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc_final): Linear(in_features=100, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# MLP 객체 생성\n",
    "batch_size = 2 # 한 번에 입력할 샘플 개수\n",
    "input_dim = 3\n",
    "hidden_dim = 100\n",
    "output_dim = 4\n",
    "\n",
    "# 모델 생성\n",
    "mlp = MultilayerPerceptron(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5e964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0.3012, 0.5836, 0.4412],\n",
      "        [0.9673, 0.3079, 0.2104]])\n",
      "\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 4])\n",
      "값: \n",
      "tensor([[-0.3718,  0.1920, -0.4468, -0.0963],\n",
      "        [-0.4084,  0.2559, -0.4296, -0.0992]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 랜덤한 입력으로 MLP 테스트하기\n",
    "import torch\n",
    "\n",
    "def describe(x):\n",
    "    print(\"타입: {}\".format(x.type()))\n",
    "    print(\"크기: {}\".format(x.shape))\n",
    "    print(\"값: \\n{}\".format(x))\n",
    "\n",
    "x_input = torch.rand(batch_size, input_dim)\n",
    "describe(x_input)\n",
    "\n",
    "print()\n",
    "\n",
    "y_output = mlp(x_input, apply_softmax=False)\n",
    "describe(y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03a9380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 4])\n",
      "값: \n",
      "tensor([[0.1999, 0.3513, 0.1855, 0.2633],\n",
      "        [0.1892, 0.3677, 0.1853, 0.2578]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# MLP 분류기로 확률 출력하기(apply_softmax=True)\n",
    "y_output = mlp(x_input, apply_softmax=True)\n",
    "describe(y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef196750",
   "metadata": {},
   "source": [
    "4.2.1 성씨 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4336b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SurnameDataset.__getitem__() 구현\n",
    "class SurnameDataset(Dataset):\n",
    "    # [코드 3-14]와 구현이 매우 비슷합니다.\n",
    "\n",
    "    def __getitem__(self, index):           \n",
    "            row = self._target_df.iloc[index]\n",
    "\n",
    "            surname_vector = self._vectorizer.vectorize(row.surname)\n",
    "\n",
    "            nationality_index = self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
    "\n",
    "            return {'x_surname': surname_vector, 'y_nationality': nationality_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff419d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8320a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9046e6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a79c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bebe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
